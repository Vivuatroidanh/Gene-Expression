{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11f46f7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # ALS Diagnosis with Machine Learning and SHAP\n",
    "# \n",
    "# This notebook provides a quick start guide for running the ALS diagnosis pipeline\n",
    "# \n",
    "# ## Overview\n",
    "# 1. Data Download and Processing\n",
    "# 2. Feature Selection (MMPC + Ridge + SFFS)\n",
    "# 3. Model Training and SHAP Analysis\n",
    "# 4. Results Interpretation\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Setup\n",
    "\n",
    "# %%\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('src')\n",
    "\n",
    "# Create necessary directories\n",
    "Path('data/raw').mkdir(parents=True, exist_ok=True)\n",
    "Path('data/processed').mkdir(parents=True, exist_ok=True)\n",
    "Path('data/results/feature_selection').mkdir(parents=True, exist_ok=True)\n",
    "Path('data/results/shap_analysis').mkdir(parents=True, exist_ok=True)\n",
    "Path('logs').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Setup completed!\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Step 1: Data Download and Processing\n",
    "\n",
    "# %%\n",
    "from data_processing.geo_downloader import GEODownloader\n",
    "\n",
    "# Initialize downloader\n",
    "downloader = GEODownloader(base_dir=\"data\")\n",
    "\n",
    "# Download and process datasets (this may take a few minutes)\n",
    "print(\"Downloading and processing GEO datasets...\")\n",
    "try:\n",
    "    gse_ids = [\"GSE112676\", \"GSE112680\"]\n",
    "    expression_data, metadata = downloader.process_datasets(gse_ids)\n",
    "    downloader.save_processed_data(expression_data, metadata)\n",
    "    \n",
    "    print(f\"‚úì Data processing completed!\")\n",
    "    print(f\"Expression data shape: {expression_data.shape}\")\n",
    "    print(f\"Sample distribution: {metadata['group'].value_counts().to_dict()}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error in data processing: {str(e)}\")\n",
    "    print(\"Please check your internet connection and try again\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Step 2: Data Exploration\n",
    "\n",
    "# %%\n",
    "# Load and explore the processed data\n",
    "expression_data = pd.read_csv(\"data/processed/combined_expression_data.csv\", index_col=0)\n",
    "metadata = pd.read_csv(\"data/processed/sample_metadata.csv\")\n",
    "\n",
    "print(\"Dataset Information:\")\n",
    "print(f\"Genes: {expression_data.shape[0]}\")\n",
    "print(f\"Samples: {expression_data.shape[1]}\")\n",
    "print(f\"Sample groups: {metadata['group'].value_counts().to_dict()}\")\n",
    "\n",
    "# Visualize sample distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "metadata['group'].value_counts().plot(kind='bar')\n",
    "plt.title('Sample Distribution')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Step 3: Feature Selection Pipeline\n",
    "\n",
    "# %%\n",
    "from feature_selection_pipeline import FeatureSelectionPipeline\n",
    "import logging\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Prepare data for feature selection\n",
    "X = expression_data.T  # Transpose: samples as rows, genes as columns\n",
    "y = metadata['group'].map({'ALS': 1, 'Control': 0})\n",
    "\n",
    "# Remove samples with missing labels\n",
    "valid_samples = ~y.isna()\n",
    "X = X[valid_samples]\n",
    "y = y[valid_samples]\n",
    "\n",
    "print(f\"Feature selection input: {X.shape[0]} samples, {X.shape[1]} genes\")\n",
    "print(f\"Class distribution: {y.value_counts().to_dict()}\")\n",
    "\n",
    "# %%\n",
    "# Run feature selection pipeline\n",
    "print(\"Running feature selection pipeline...\")\n",
    "print(\"This may take 15-30 minutes depending on your hardware...\")\n",
    "\n",
    "pipeline = FeatureSelectionPipeline()\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "# Get results\n",
    "best_features = pipeline.get_selected_features()\n",
    "best_algorithm = pipeline.get_best_algorithm()\n",
    "best_score = pipeline.best_config_[3]\n",
    "\n",
    "print(f\"\\nüéØ FEATURE SELECTION RESULTS:\")\n",
    "print(f\"Best algorithm: {best_algorithm}\")\n",
    "print(f\"Selected features: {len(best_features)}\")\n",
    "print(f\"Best CV score: {best_score:.4f}\")\n",
    "\n",
    "print(f\"\\nSelected genes:\")\n",
    "for i, gene in enumerate(best_features, 1):\n",
    "    print(f\"  {i:2d}. {gene}\")\n",
    "\n",
    "# Save results\n",
    "pipeline.save_results(\"data/results/feature_selection\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Step 4: SHAP Analysis\n",
    "\n",
    "# %%\n",
    "from shap_interpretability import SHAPAnalyzer\n",
    "\n",
    "# Load feature selection results\n",
    "import pickle\n",
    "with open(\"data/results/feature_selection/pipeline_results.pkl\", 'rb') as f:\n",
    "    pipeline_results = pickle.load(f)\n",
    "\n",
    "best_config = pipeline_results['best_config']\n",
    "selected_features = best_config['features']\n",
    "best_algorithm = best_config['algorithm']\n",
    "\n",
    "print(f\"Loading SHAP analysis for {best_algorithm} with {len(selected_features)} features\")\n",
    "\n",
    "# Prepare data\n",
    "X_selected = expression_data.T[selected_features]\n",
    "y = metadata['group'].map({'ALS': 1, 'Control': 0})\n",
    "\n",
    "# Remove missing labels\n",
    "valid_samples = ~y.isna()\n",
    "X_selected = X_selected[valid_samples]\n",
    "y = y[valid_samples]\n",
    "\n",
    "# %%\n",
    "# Initialize and run SHAP analysis\n",
    "print(\"Running SHAP analysis...\")\n",
    "\n",
    "analyzer = SHAPAnalyzer(model_type=best_algorithm)\n",
    "\n",
    "# Train model\n",
    "training_results = analyzer.fit(X_selected, y, test_size=0.1)\n",
    "print(f\"Model Performance:\")\n",
    "print(f\"  Test Accuracy: {training_results['test_accuracy']:.4f}\")\n",
    "print(f\"  Test AUC: {training_results['test_auc']:.4f}\")\n",
    "\n",
    "# Create SHAP explainer and calculate values\n",
    "print(\"Creating SHAP explainer...\")\n",
    "analyzer.create_shap_explainer(background_samples=50)\n",
    "\n",
    "print(\"Calculating SHAP values...\")\n",
    "analyzer.calculate_shap_values(max_samples=100)\n",
    "\n",
    "print(\"‚úì SHAP analysis completed!\")\n",
    "\n",
    "# %%\n",
    "# Generate SHAP visualizations\n",
    "output_dir = \"data/results/shap_analysis\"\n",
    "\n",
    "print(\"Generating SHAP visualizations...\")\n",
    "\n",
    "# Feature importance plot\n",
    "importance_df = analyzer.plot_feature_importance(output_dir, show_plot=True)\n",
    "\n",
    "# Summary plot\n",
    "analyzer.plot_summary(output_dir, show_plot=True)\n",
    "\n",
    "print(\"‚úì Visualizations generated!\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Step 5: Individual Sample Analysis\n",
    "\n",
    "# %%\n",
    "# Analyze individual samples\n",
    "print(\"Analyzing individual samples...\")\n",
    "\n",
    "# Show waterfall plots for a few samples\n",
    "analyzer.plot_waterfall(sample_idx=0, output_dir=output_dir, show_plot=True)\n",
    "analyzer.plot_waterfall(sample_idx=1, output_dir=output_dir, show_plot=True)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Step 6: Gene Interaction Analysis\n",
    "\n",
    "# %%\n",
    "# Analyze gene interactions\n",
    "print(\"Analyzing gene interactions...\")\n",
    "correlation_matrix = analyzer.analyze_gene_interactions(output_dir)\n",
    "\n",
    "print(\"Top gene pairs with strongest interactions:\")\n",
    "# Find top correlations (excluding diagonal)\n",
    "mask = np.triu(np.ones_like(correlation_matrix), k=1).astype(bool)\n",
    "correlations = correlation_matrix.where(mask).stack().sort_values(key=abs, ascending=False)\n",
    "print(correlations.head(10))\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Step 7: Comprehensive Report\n",
    "\n",
    "# %%\n",
    "# Generate comprehensive interpretation report\n",
    "print(\"Generating comprehensive interpretation report...\")\n",
    "report = analyzer.generate_interpretation_report(output_dir)\n",
    "\n",
    "print(\"\\nüéØ FINAL RESULTS SUMMARY:\")\n",
    "print(f\"Model: {best_algorithm}\")\n",
    "print(f\"Test Accuracy: {training_results['test_accuracy']:.4f}\")\n",
    "print(f\"Test AUC: {training_results['test_auc']:.4f}\")\n",
    "print(f\"Number of features: {len(selected_features)}\")\n",
    "\n",
    "print(f\"\\nTop 10 Most Important Genes:\")\n",
    "for i, gene_info in enumerate(report['top_genes'][:10], 1):\n",
    "    print(f\"  {i:2d}. {gene_info['gene']:15s} - Importance: {gene_info['mean_abs_shap']:.4f}\")\n",
    "\n",
    "print(f\"\\nMost Important Gene: {report['most_important_gene']['name']}\")\n",
    "print(f\"Importance Score: {report['most_important_gene']['importance']:.4f}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Step 8: Results Summary\n",
    "\n",
    "# %%\n",
    "# Display final results\n",
    "print(\"=\"*60)\n",
    "print(\"ALS DIAGNOSIS PIPELINE - COMPLETED\")\n",
    "print(\"=\"*60)\n",
    "print(\"‚úì Data downloaded and processed\")\n",
    "print(\"‚úì Feature selection completed\")\n",
    "print(\"‚úì Model training finished\")\n",
    "print(\"‚úì SHAP analysis completed\")\n",
    "print(\"‚úì Comprehensive report generated\")\n",
    "\n",
    "print(f\"\\nüìä KEY METRICS:\")\n",
    "print(f\"Selected Genes: {len(selected_features)}\")\n",
    "print(f\"Best Algorithm: {best_algorithm}\")\n",
    "print(f\"Cross-validation Score: {best_score:.4f}\")\n",
    "print(f\"Test Accuracy: {training_results['test_accuracy']:.4f}\")\n",
    "print(f\"Test AUC: {training_results['test_auc']:.4f}\")\n",
    "\n",
    "print(f\"\\nüìÅ Results Location:\")\n",
    "print(f\"  - Feature Selection: data/results/feature_selection/\")\n",
    "print(f\"  - SHAP Analysis: data/results/shap_analysis/\")\n",
    "print(f\"  - Visualizations: PNG files in results directories\")\n",
    "\n",
    "print(f\"\\nüß¨ Top 5 Genes for ALS Diagnosis:\")\n",
    "for i, gene_info in enumerate(report['top_genes'][:5], 1):\n",
    "    print(f\"  {i}. {gene_info['gene']} (importance: {gene_info['mean_abs_shap']:.4f})\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Next Steps\n",
    "# \n",
    "# 1. **Biological Validation**: Research the biological roles of top-ranked genes\n",
    "# 2. **External Validation**: Test on independent datasets\n",
    "# 3. **Clinical Integration**: Develop clinical decision support tools\n",
    "# 4. **Publication**: Document findings for scientific publication\n",
    "# \n",
    "# ## Files Generated\n",
    "# \n",
    "# - `data/results/feature_selection/`: Complete feature selection results\n",
    "# - `data/results/shap_analysis/`: SHAP interpretability analysis\n",
    "# - Various CSV files with detailed gene rankings and statistics\n",
    "# - PNG visualization files for presentations and publications\n",
    "\n",
    "# %%"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
